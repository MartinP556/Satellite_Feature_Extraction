{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import data_cleaning\n",
    "from modelling_fctns import double_logistic, normalized_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_phenological_stages(ndvi, doy, a=0.10):\n",
    "    # Step 2: Determine start, end, and mid-point of the season\n",
    "\n",
    "    # Determine NDVI threshold\n",
    "    ndvi_max = np.max(ndvi)\n",
    "    ndvi_base = np.min(ndvi[ndvi > 0])\n",
    "    ndvi_threshold = a * (ndvi_max - ndvi_base) + ndvi_base\n",
    "\n",
    "    # Determine start, end, and mid-point of the season\n",
    "    doy_start = doy[np.argmax(ndvi > ndvi_threshold)]\n",
    "    doy_end = doy[-(np.argmax(ndvi[::-1] > ndvi_threshold)+1)]  # Search in reverse for last occurrence\n",
    "    doy_midpoint = int(0.5 * (doy_start + doy_end) + doy_start)\n",
    "\n",
    "    return ndvi_threshold, doy_start, doy_end, doy_midpoint\n",
    "\n",
    "def calculate_small_integral(ndvi, doy, doy_midpoint, n=100):\n",
    "    # Step 3: Calculate the small integral (summed NDVI, sNDVI)\n",
    "    # Determine crop greenup date\n",
    "    doy_greenup = doy_midpoint - n\n",
    "\n",
    "    # Calculate the small integral (sNDVI)\n",
    "    ndvi_base = np.min(ndvi[ndvi > 0])\n",
    "    s_ndvi = (ndvi[doy >= doy_greenup] - ndvi_base)\n",
    "\n",
    "    return s_ndvi\n",
    "\n",
    "def get_biomass(df_ndvi, plotting=False):\n",
    "    # Convert date to datetime\n",
    "    df_ndvi['date'] = pd.to_datetime(df_ndvi['date'])\n",
    "    #sort by date\n",
    "    df_ndvi = df_ndvi.sort_values('date')\n",
    "    df_ndvi = df_ndvi.loc[df_ndvi['NDVI'] != -9999]\n",
    "    #groupby day and mean\n",
    "    df_ndvi = df_ndvi[['NDVI','date', 'cs', 'cs_cdf']].groupby('date').mean().reset_index()\n",
    "    #mask out if cs>0.55\n",
    "    df_ndvi = df_ndvi.loc[df_ndvi['cs'] > 0.55]\n",
    "\n",
    "    #get start and end date, truncate time\n",
    "    start_year = df_ndvi['date'].dt.year.values[0]\n",
    "    start_dt = df_ndvi['date'].dt.normalize().values[0]\n",
    "    end_dt = df_ndvi['date'].dt.normalize().values[-1]\n",
    "    #get daily timerange from start to end\n",
    "    date_range = pd.date_range(start=start_dt, end=end_dt, freq='D')\n",
    "\n",
    "    #interpolate NDVI for every day\n",
    "    df_ndvi = df_ndvi.set_index('date')\n",
    "    df_ndvi = df_ndvi[['NDVI','cs', 'cs_cdf']].resample('D').mean()\n",
    "    df_ndvi = df_ndvi.interpolate(method='linear')\n",
    "    df_ndvi = df_ndvi.reset_index()\n",
    "\n",
    "    doy = df_ndvi['date'].dt.dayofyear.values #np.array([i for i in range(1, 366)])\n",
    "    first_doy = doy[0]\n",
    "    days_elapsed = np.array(range(len(doy)))\n",
    "\n",
    "    # Step 1: Interpolate the time series\n",
    "    ndvi_interp = df_ndvi['NDVI'].values.copy()\n",
    "    cs_interp = df_ndvi['cs'].values.copy()\n",
    "\n",
    "    # Check for NaNs and negative numbers in NDVI time series and return nans if either condition is met - SAJchange\n",
    "    has_nan = any(np.isnan(x) for x in ndvi_interp if isinstance(x, (int, float)))\n",
    "    #has_negative = any(x < 0 for x in ndvi_interp if isinstance(x, (int, float)))\n",
    "    #if has_nan or has_negative:\n",
    "    if has_nan:\n",
    "        print(\"Error: The list contains NaN values.\")\n",
    "        s_ndvi_crop = date_range = np.nan # = ndvi_interp sajchange - addition of ndvi_interp here\n",
    "        return np.cumsum(s_ndvi_crop), date_range#, ndvi_interp\n",
    "\n",
    "    #interpolate_ndvi(ndvi_values, doy)\n",
    "    # smooth the time series with savitzky-golay filter\n",
    "    ndvi_interp = savgol_filter(ndvi_interp, 51, 2)\n",
    "\n",
    "    # Step 2: Determine start, end, and mid-point of the season\n",
    "    ndvi_threshold, doy_start, doy_end, doy_midpoint = determine_phenological_stages(ndvi_interp, days_elapsed)\n",
    "\n",
    "    # Step 3: Calculate the small integral (summed NDVI, sNDVI)\n",
    "    n = 100\n",
    "    s_ndvi = calculate_small_integral(ndvi_interp, days_elapsed, doy_midpoint, n)\n",
    "\n",
    "    #set start_dt to be greenup which is midpoint-n days\n",
    "    start_dt = start_dt + pd.Timedelta(days=doy_midpoint) - pd.Timedelta(days=n)\n",
    "\n",
    "    #if start_dt earlier than start of date range, backfill sndvi\n",
    "    if start_dt <= date_range[0]:\n",
    "        s_ndvi_crop = np.zeros(len(pd.date_range(start=start_dt, end=end_dt, freq='D')))\n",
    "        num_bfill_days = len(s_ndvi_crop) - len(s_ndvi)\n",
    "        if len(pd.date_range(start=start_dt, end=end_dt, freq='D')) < len(date_range):\n",
    "            s_ndvi_crop[num_bfill_days:] = s_ndvi[:len(pd.date_range(start=start_dt, end=end_dt, freq='D'))]\n",
    "        s_ndvi_crop[num_bfill_days:] = s_ndvi\n",
    "        date_range = pd.date_range(start=start_dt, end=end_dt, freq='D')\n",
    "    else:\n",
    "        s_ndvi_crop = s_ndvi\n",
    "        date_range = pd.date_range(start=start_dt, end=end_dt, freq='D')\n",
    "\n",
    "    #1% chance of plotting == 1 else 0\n",
    "    if plotting:\n",
    "        plt.figure(figsize=(12,6))\n",
    "\n",
    "        # Visualization (optional)\n",
    "        plt.plot(days_elapsed+first_doy, ndvi_values, label='Original NDVI')\n",
    "        plt.plot(days_elapsed+first_doy, ndvi_interp, label='Interpolated NDVI')\n",
    "        plt.plot(days_elapsed+first_doy, cs_interp, 'r*', alpha=.25, label='Cloud Score')\n",
    "        plt.axhline(y=ndvi_threshold, color='r', linestyle='--', label='NDVI Threshold')\n",
    "        plt.axvline(x=doy_start+first_doy, color='g', linestyle='--', label='Start of Season')\n",
    "        plt.axvline(x=doy_end+first_doy, color='b', linestyle='--', label='End of Season')\n",
    "        plt.axvline(x=doy_midpoint+first_doy, color='m', linestyle='--', label='Midpoint of Season')\n",
    "        plt.title('NDVI Time Series and Phenological Stages')\n",
    "        plt.xlabel('Day of Year')\n",
    "        plt.ylabel('NDVI')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Print results\n",
    "        print(f'NDVI Threshold: {ndvi_threshold}')\n",
    "        print(f'Start of Season (DOY): {doy_start+first_doy}')\n",
    "        print(f'End of Season (DOY): {doy_end+first_doy}')\n",
    "        print(f'Midpoint of Season (DOY): {doy_midpoint+first_doy}')\n",
    "        print(f'Small Integral (sNDVI): {np.sum(s_ndvi)}')\n",
    "\n",
    "    assert len(date_range) == len(s_ndvi_crop), f'date range and s_ndvi length mismatch, {len(date_range)} != {len(s_ndvi_crop)}'\n",
    "    return np.cumsum(s_ndvi_crop), date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = pd.read_csv('C:\\\\Users\\\\wlwc1989\\\\Documents\\\\Phenology_Test_Notebooks\\\\earth_engine_MP\\\\Saved_files\\\\MODIS\\\\Germany\\\\satdata0.csv')\n",
    "ds2 = data_cleaning.add_SOS_to_df(ds2)\n",
    "ds2 = data_cleaning.add_EOS_to_df(ds2)\n",
    "ds2['NDVI'] = normalized_difference(ds2['median sur_refl_b02'], ds2['median sur_refl_b01'])\n",
    "max_value_interpolated = data_cleaning.map_max_value_int(ds2, window_size=8)\n",
    "array_input = data_cleaning.make_df_samples(max_value_interpolated, sample_number = 1000, m_window_size = 5)\n",
    "sampled_locs_input = data_cleaning.make_tensor_from_timeseries(max_value_interpolated, sample_number = 100, m_window_size = 5, format_choice = 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>Stations_Id</th>\n",
       "      <th>median sur_refl_b01</th>\n",
       "      <th>median sur_refl_b02</th>\n",
       "      <th>median sur_refl_b03</th>\n",
       "      <th>median sur_refl_b04</th>\n",
       "      <th>formatted_time</th>\n",
       "      <th>SOS</th>\n",
       "      <th>EOS</th>\n",
       "      <th>NDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1577836800000</td>\n",
       "      <td>54.7833</td>\n",
       "      <td>9.4333</td>\n",
       "      <td>7501</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>2020-01-01 00:00:00+00:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.124088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1578096000000</td>\n",
       "      <td>54.7833</td>\n",
       "      <td>9.4333</td>\n",
       "      <td>7501</td>\n",
       "      <td>502.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>2020-01-04 00:00:00+00:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.169562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1579392000000</td>\n",
       "      <td>54.7833</td>\n",
       "      <td>9.4333</td>\n",
       "      <td>7501</td>\n",
       "      <td>827.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>2020-01-19 00:00:00+00:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.251922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>1580860800000</td>\n",
       "      <td>54.7833</td>\n",
       "      <td>9.4333</td>\n",
       "      <td>7501</td>\n",
       "      <td>546.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>2020-02-05 00:00:00+00:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.306226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>1582848000000</td>\n",
       "      <td>54.7833</td>\n",
       "      <td>9.4333</td>\n",
       "      <td>7501</td>\n",
       "      <td>146.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2020-02-28 00:00:00+00:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.474820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15341</th>\n",
       "      <td>1054</td>\n",
       "      <td>1669939200000</td>\n",
       "      <td>54.8000</td>\n",
       "      <td>9.6333</td>\n",
       "      <td>7569</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>2068.0</td>\n",
       "      <td>3783.0</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>2022-12-02 00:00:00+00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-0.102820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15342</th>\n",
       "      <td>1063</td>\n",
       "      <td>1670716800000</td>\n",
       "      <td>54.8000</td>\n",
       "      <td>9.6333</td>\n",
       "      <td>7569</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>3394.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>2022-12-11 00:00:00+00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.337010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15343</th>\n",
       "      <td>1068</td>\n",
       "      <td>1671148800000</td>\n",
       "      <td>54.8000</td>\n",
       "      <td>9.6333</td>\n",
       "      <td>7569</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>4384.0</td>\n",
       "      <td>4232.0</td>\n",
       "      <td>3730.0</td>\n",
       "      <td>2022-12-16 00:00:00+00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.118082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15344</th>\n",
       "      <td>1075</td>\n",
       "      <td>1671753600000</td>\n",
       "      <td>54.8000</td>\n",
       "      <td>9.6333</td>\n",
       "      <td>7569</td>\n",
       "      <td>533.0</td>\n",
       "      <td>2399.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>2022-12-23 00:00:00+00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.636426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15345</th>\n",
       "      <td>1079</td>\n",
       "      <td>1672099200000</td>\n",
       "      <td>54.8000</td>\n",
       "      <td>9.6333</td>\n",
       "      <td>7569</td>\n",
       "      <td>468.0</td>\n",
       "      <td>2364.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>2022-12-27 00:00:00+00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.669492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15346 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           Time      lat     lon  Stations_Id  \\\n",
       "0               0  1577836800000  54.7833  9.4333         7501   \n",
       "1               3  1578096000000  54.7833  9.4333         7501   \n",
       "2              18  1579392000000  54.7833  9.4333         7501   \n",
       "3              35  1580860800000  54.7833  9.4333         7501   \n",
       "4              58  1582848000000  54.7833  9.4333         7501   \n",
       "...           ...            ...      ...     ...          ...   \n",
       "15341        1054  1669939200000  54.8000  9.6333         7569   \n",
       "15342        1063  1670716800000  54.8000  9.6333         7569   \n",
       "15343        1068  1671148800000  54.8000  9.6333         7569   \n",
       "15344        1075  1671753600000  54.8000  9.6333         7569   \n",
       "15345        1079  1672099200000  54.8000  9.6333         7569   \n",
       "\n",
       "       median sur_refl_b01  median sur_refl_b02  median sur_refl_b03  \\\n",
       "0                   1080.0               1386.0               1118.0   \n",
       "1                    502.0                707.0                589.0   \n",
       "2                    827.0               1384.0                542.0   \n",
       "3                    546.0               1028.0                353.0   \n",
       "4                    146.0                410.0                 83.0   \n",
       "...                    ...                  ...                  ...   \n",
       "15341               2542.0               2068.0               3783.0   \n",
       "15342               1683.0               3394.0               1963.0   \n",
       "15343               3458.0               4384.0               4232.0   \n",
       "15344                533.0               2399.0                608.0   \n",
       "15345                468.0               2364.0                281.0   \n",
       "\n",
       "       median sur_refl_b04             formatted_time    SOS    EOS      NDVI  \n",
       "0                   1089.0  2020-01-01 00:00:00+00:00  103.0  297.0  0.124088  \n",
       "1                    537.0  2020-01-04 00:00:00+00:00  103.0  297.0  0.169562  \n",
       "2                    786.0  2020-01-19 00:00:00+00:00  103.0  297.0  0.251922  \n",
       "3                    525.0  2020-02-05 00:00:00+00:00  103.0  297.0  0.306226  \n",
       "4                     68.0  2020-02-28 00:00:00+00:00  103.0  297.0  0.474820  \n",
       "...                    ...                        ...    ...    ...       ...  \n",
       "15341               3158.0  2022-12-02 00:00:00+00:00  104.0  299.0 -0.102820  \n",
       "15342               1900.0  2022-12-11 00:00:00+00:00  104.0  299.0  0.337010  \n",
       "15343               3730.0  2022-12-16 00:00:00+00:00  104.0  299.0  0.118082  \n",
       "15344                705.0  2022-12-23 00:00:00+00:00  104.0  299.0  0.636426  \n",
       "15345                642.0  2022-12-27 00:00:00+00:00  104.0  299.0  0.669492  \n",
       "\n",
       "[15346 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'formatted_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'formatted_time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df_time_adjust \u001b[38;5;241m=\u001b[39m ds2\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformatted_time\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual_time\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m----> 2\u001b[0m df_time_adjust[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime from edge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df_time_adjust[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m df_time_adjust[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformatted_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdays\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'formatted_time'"
     ]
    }
   ],
   "source": [
    "df_time_adjust = ds2.reset_index().rename(columns={'formatted_time': 'actual_time'}).reset_index()\n",
    "df_time_adjust['time from edge'] = (df_time_adjust['actual_time'] - df_time_adjust['formatted_time']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
